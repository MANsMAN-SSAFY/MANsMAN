{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\ssafy\\desktop\\fastapi\\venv\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in c:\\users\\ssafy\\desktop\\fastapi\\venv\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wrapt==1.14.1 in c:\\users\\ssafy\\desktop\\fastapi\\venv\\lib\\site-packages (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# tf.saved_model.save를 사용하기 위해\n",
    "%pip install wrapt==1.14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 250 images of acnes.\n",
      "There are 250 images of blackheads.\n",
      "There are 250 images of wrinkles.\n"
     ]
    }
   ],
   "source": [
    "source = 'dataset'\n",
    "sourceAcnes = os.path.join(source, 'acnes')\n",
    "sourceBlackheads = os.path.join(source, 'blackheads')\n",
    "sourceWrinkles = os.path.join(source, 'wrinkles')\n",
    "\n",
    "print(f\"There are {len(os.listdir(sourceAcnes))} images of acnes.\")\n",
    "print(f\"There are {len(os.listdir(sourceBlackheads))} images of blackheads.\")\n",
    "print(f\"There are {len(os.listdir(sourceWrinkles))} images of wrinkles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 다음의 root_dir를 생성한다.\n",
    "root_dir = 'train-validation'\n",
    "\n",
    "# Empty directory to prevent FileExistsError if the function is run several times\n",
    "if os.path.exists(root_dir):\n",
    "    shutil.rmtree(root_dir)\n",
    "\n",
    "# train, validation dir를 생성한다\n",
    "def create_train_val_dirs(root_path):\n",
    "    # train and validation directories for skin-case\n",
    "    train_dir = os.path.join(root_dir, 'training')\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    val_dir = os.path.join(root_dir, 'validation')\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "    # train acne\n",
    "    train_acnes_dir = os.path.join(train_dir, 'acnes')\n",
    "    os.makedirs(train_acnes_dir, exist_ok=True)\n",
    "    # train blackhead\n",
    "    train_blackheads_dir = os.path.join(train_dir, 'blackheads')\n",
    "    os.makedirs(train_blackheads_dir, exist_ok=True)\n",
    "    # train wrinkle\n",
    "    train_wrinkles_dir = os.path.join(train_dir, 'wrinkles')\n",
    "    os.makedirs(train_wrinkles_dir, exist_ok=True)\n",
    "\n",
    "    # validation acne\n",
    "    val_acnes_dir = os.path.join(val_dir, 'acnes')\n",
    "    os.makedirs(val_acnes_dir, exist_ok=True)\n",
    "    # validation blackhead\n",
    "    val_blackheads_dir = os.path.join(val_dir, 'blackheads')\n",
    "    os.makedirs(val_blackheads_dir, exist_ok=True)\n",
    "    # validation wrinkle\n",
    "    val_wrinkles_dir = os.path.join(val_dir, 'wrinkles')\n",
    "    os.makedirs(val_wrinkles_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    create_train_val_dirs(root_path=root_dir)\n",
    "except FileExistsError:\n",
    "    print(\"FileExistsError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset을 training과 validiation으로 split\n",
    "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
    "  files = []\n",
    "  for filename in os.listdir(SOURCE_DIR):\n",
    "    file = SOURCE_DIR + filename\n",
    "    if os.path.getsize(file) > 0:\n",
    "      files.append(filename)\n",
    "    else:\n",
    "      print(filename + ' 의 길이가 0이므로 무시합니다')\n",
    "\n",
    "    all_files = len(files)\n",
    "    train_length = int(all_files * SPLIT_SIZE)\n",
    "    test_length = int(all_files - train_length)\n",
    "    shuffled = random.sample(files, all_files)\n",
    "    train_set = shuffled[0:train_length]\n",
    "    test_set = shuffled[train_length:]\n",
    "\n",
    "  for filename in train_set:\n",
    "    src_file = SOURCE_DIR + filename\n",
    "    dest_file = TRAINING_DIR + filename\n",
    "    copyfile(src_file, dest_file)\n",
    "\n",
    "  for filename in test_set:\n",
    "    src_file = SOURCE_DIR + filename\n",
    "    dest_file = VALIDATION_DIR + filename\n",
    "    copyfile(src_file, dest_file)\n",
    "\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ACNES_SOURCE_DIR = \"dataset/acnes/\"\n",
    "BLACKHEADS_SOURCE_DIR = \"dataset/blackheads/\"\n",
    "WRINKLES_SOURCE_DIR = \"dataset/wrinkles/\"\n",
    "\n",
    "TRAINING_DIR = \"train-validation/training\"\n",
    "VALIDATION_DIR = \"train-validation/validation\"\n",
    "\n",
    "TRAINING_ACNES_DIR = os.path.join(TRAINING_DIR, \"acnes/\")\n",
    "VALIDATION_ACNES_DIR = os.path.join(VALIDATION_DIR, \"acnes/\")\n",
    "\n",
    "TRAINING_BLACKHEADS_DIR = os.path.join(TRAINING_DIR, \"blackheads/\")\n",
    "VALIDATION_BLACKHEADS_DIR = os.path.join(VALIDATION_DIR, \"blackheads/\")\n",
    "\n",
    "TRAINING_WRINKLES_DIR = os.path.join(TRAINING_DIR, \"wrinkles/\")\n",
    "VALIDATION_WRINKLES_DIR = os.path.join(VALIDATION_DIR, \"wrinkles/\")\n",
    "\n",
    "# 이 cell을 여러 번 돌릴 경우에 대비\n",
    "if len(os.listdir(TRAINING_WRINKLES_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_WRINKLES_DIR):\n",
    "    os.remove(file.path)\n",
    "\n",
    "if len(os.listdir(VALIDATION_WRINKLES_DIR)) > 0:\n",
    "  for file in os.scandir(VALIDATION_WRINKLES_DIR):\n",
    "    os.remove(file.path)\n",
    "\n",
    "# train: validiation = 8:2\n",
    "split_size = .8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original acne's directory has 250 images\n",
      "\n",
      "\n",
      "Original blackhead's directory has 250 images\n",
      "\n",
      "\n",
      "Original winkle's directory has 250 images\n",
      "\n",
      "\n",
      "There are 200 images of acnes for training\n",
      "\n",
      "\n",
      "There are 50 images of acnes for validation\n",
      "\n",
      "\n",
      "There are 200 images of blackheads for training\n",
      "\n",
      "\n",
      "There are 50 images of blackheads for validation\n",
      "\n",
      "\n",
      "There are 200 images of wrinkles for training\n",
      "\n",
      "\n",
      "There are 50 images of wrinkles for validation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# dataset을 split해서 training과 validation을 구한다 \n",
    "split_data(ACNES_SOURCE_DIR, TRAINING_ACNES_DIR, VALIDATION_ACNES_DIR, split_size)\n",
    "split_data(BLACKHEADS_SOURCE_DIR, TRAINING_BLACKHEADS_DIR, VALIDATION_BLACKHEADS_DIR, split_size)\n",
    "split_data(WRINKLES_SOURCE_DIR, TRAINING_WRINKLES_DIR, VALIDATION_WRINKLES_DIR, split_size)\n",
    "\n",
    "print(f\"\\n\\nOriginal acne's directory has {len(os.listdir(ACNES_SOURCE_DIR))} images\")\n",
    "print(f\"\\n\\nOriginal blackhead's directory has {len(os.listdir(BLACKHEADS_SOURCE_DIR))} images\")\n",
    "print(f\"\\n\\nOriginal winkle's directory has {len(os.listdir(WRINKLES_SOURCE_DIR))} images\")\n",
    "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_WRINKLES_DIR))} images of acnes for training\")\n",
    "print(f\"\\n\\nThere are {len(os.listdir(VALIDATION_WRINKLES_DIR))} images of acnes for validation\")\n",
    "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_BLACKHEADS_DIR))} images of blackheads for training\")\n",
    "print(f\"\\n\\nThere are {len(os.listdir(VALIDATION_BLACKHEADS_DIR))} images of blackheads for validation\")\n",
    "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_WRINKLES_DIR))} images of wrinkles for training\")\n",
    "print(f\"\\n\\nThere are {len(os.listdir(VALIDATION_WRINKLES_DIR))} images of wrinkles for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "  \"\"\"\n",
    "  train, validation generator 생성\n",
    "\n",
    "  \"\"\"\n",
    "  train_datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                                     rotation_range=40,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True,\n",
    "                                     fill_mode='nearest')\n",
    "\n",
    "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=32,\n",
    "                                                      class_mode='categorical',\n",
    "                                                      target_size=(150, 150))\n",
    "\n",
    "\n",
    "  validation_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                                batch_size=32,\n",
    "                                                                class_mode='categorical',\n",
    "                                                                target_size=(150, 150))\n",
    "\n",
    "  return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 3 classes.\n",
      "Found 150 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# generator 테스트\n",
    "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도가 90%가 넘어가면 더 이상 모델 훈련을 하지 않는다\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_acc')>0.90):\n",
    "      print(\"\\nReached 90.0% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "def create_model():\n",
    "\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "      tf.keras.layers.Flatten(),\n",
    "\n",
    "      tf.keras.layers.Dense(512, activation='relu'),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(3, activation='sigmoid') \n",
    "\n",
    "  ])\n",
    "\n",
    "\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\fastapi\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18496</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,470,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18496\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m9,470,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m32,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,527,075</span> (36.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,527,075\u001b[0m (36.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,527,075</span> (36.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,527,075\u001b[0m (36.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 정보\n",
    "model = create_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\fastapi\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 - 6s - 291ms/step - acc: 0.5850 - loss: 0.5348 - val_acc: 0.6867 - val_loss: 0.3237\n",
      "Epoch 2/100\n",
      "19/19 - 4s - 230ms/step - acc: 0.7633 - loss: 0.3240 - val_acc: 0.8333 - val_loss: 0.2530\n",
      "Epoch 3/100\n",
      "19/19 - 4s - 228ms/step - acc: 0.7800 - loss: 0.2917 - val_acc: 0.6733 - val_loss: 0.3141\n",
      "Epoch 4/100\n",
      "19/19 - 4s - 229ms/step - acc: 0.8117 - loss: 0.2647 - val_acc: 0.9000 - val_loss: 0.1940\n",
      "Epoch 5/100\n",
      "\n",
      "Reached 90.0% accuracy so cancelling training!\n",
      "19/19 - 4s - 231ms/step - acc: 0.8650 - loss: 0.2135 - val_acc: 0.9133 - val_loss: 0.1444\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "callbacks = myCallback()\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=100,# epoch가 100일 때 정확도가 90% 이상\n",
    "                    verbose=2,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: acne-blackhead-wrinkle-saved-model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: acne-blackhead-wrinkle-saved-model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"acne-blackhead-wrinkle-saved-model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
